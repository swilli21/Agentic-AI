{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DhKQ2zYApOOW"
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "!pip install -qU langchain langchain-google-genai google-generativeai==0.8.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community langchain-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV_CXZzo618q",
        "outputId": "70f6c105-58c6-41c2-b7e6-6c17c1aa1f56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.12)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.9)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (26.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import langchain, langchain_core\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, trim_messages\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory"
      ],
      "metadata": {
        "id": "_ImJTlWEpWeM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set API Key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GEMINI_API_KEY_DEFAULT\")"
      ],
      "metadata": {
        "id": "6VACpg8EpY-E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create Gemini LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "EcoLuYujpcHu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define a Trimmer (The new \"Window Memory\")\n",
        "# This replaces k=2 by keeping the last 5 messages (adjust as needed)\n",
        "trimmer = trim_messages(\n",
        "    max_tokens=5, # Simplified here for \"last few messages\" logic\n",
        "    strategy=\"last\",\n",
        "    token_counter=len, # Counts messages rather than raw tokens for simplicity\n",
        "    include_system=True,\n",
        "    allow_partial=False,\n",
        "    start_on=\"human\",\n",
        ")"
      ],
      "metadata": {
        "id": "lRwSG2a5pktM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Define the Prompt Template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "hOAMwGu9poRQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Create the Chain using LCEL\n",
        "# We use the trimmer *inside* the history management or as part of the chain\n",
        "chain = prompt | llm\n"
      ],
      "metadata": {
        "id": "qJWGijnXpsqb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Manage History (The \"Memory\" container)\n",
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str):\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "wrapped_chain = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "9S2aT3iM84Lp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"user_1\"}}\n",
        "\n",
        "# Step 1: Name input\n",
        "name = input(\"Enter your name: \")\n",
        "wrapped_chain.invoke({\"input\": f\"My name is {name}. Please remember it and greet me.\"}, config)\n",
        "\n",
        "# Step 2: Topic 1\n",
        "topic1 = wrapped_chain.invoke({\"input\": \"Tell me something interesting about Mars.\"}, config)\n",
        "print(\"\\nTopic 1:\\n\", topic1.content)\n",
        "\n",
        "# Step 3: Topic 2\n",
        "topic2 = wrapped_chain.invoke({\"input\": \"Now explain how plants make food.\"}, config)\n",
        "print(\"\\nTopic 2:\\n\", topic2.content)\n",
        "\n",
        "# Step 4: Topic 3\n",
        "topic3 = wrapped_chain.invoke({\"input\": \"Now explain Where do we apply calculus in Data Science?.\"}, config)\n",
        "print(\"\\nTopic 3:\\n\", topic3.content)\n",
        "\n",
        "# Step 5: The Test (Will it remember the name?)\n",
        "# Because of the sliding window/trimming, the earliest messages will be dropped.\n",
        "followup = wrapped_chain.invoke({\"input\": \"Do you remember my name?\"}, config)\n",
        "print(\"\\nFollow-up Response:\\n\", followup.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulVtuaWqpv2O",
        "outputId": "5d8e113e-62aa-4c7d-f448-524afd53d46d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your name: John\n",
            "\n",
            "Topic 1:\n",
            " Did you know that Mars is home to the **largest volcano in the entire solar system**?\n",
            "\n",
            "It's called **Olympus Mons**, and it's a massive shield volcano. To give you an idea of its scale:\n",
            "\n",
            "*   It's about **25 kilometers (16 miles) high**, which is nearly three times the height of Mount Everest!\n",
            "*   It has a diameter of about **600 kilometers (370 miles)**, making it wide enough to cover an area roughly the size of Arizona.\n",
            "\n",
            "It's an incredible geological feature!\n",
            "\n",
            "Topic 2:\n",
            " That's a great question! Plants are incredible because they can make their own food through a process called **photosynthesis**.\n",
            "\n",
            "Think of a plant as a tiny, incredibly efficient food factory. Here's how it works:\n",
            "\n",
            "1.  **The Ingredients (What a plant needs):**\n",
            "    *   **Sunlight:** This is the energy source, just like electricity for a factory. Plants absorb sunlight, usually through their leaves.\n",
            "    *   **Water:** Absorbed from the soil through its roots and transported up to the leaves.\n",
            "    *   **Carbon Dioxide:** A gas it takes in from the air through tiny pores on its leaves called **stomata**.\n",
            "\n",
            "2.  **The \"Kitchen\" (Where it happens):**\n",
            "    *   The magic happens mainly in the plant's **leaves**, specifically in tiny structures within the cells called **chloroplasts**.\n",
            "    *   Inside chloroplasts is a green pigment called **chlorophyll**. This is what gives plants their green color, and its main job is to capture the energy from sunlight.\n",
            "\n",
            "3.  **The \"Cooking\" Process (The transformation):**\n",
            "    *   Chlorophyll captures the energy from sunlight.\n",
            "    *   This captured energy is then used to combine the water and carbon dioxide. It's like using energy to cook ingredients together.\n",
            "\n",
            "4.  **The \"Food\" and Byproduct (What is made):**\n",
            "    *   The \"food\" it makes is a type of **sugar called glucose**. This sugar is the plant's energy source, just like the food we eat gives us energy. Plants use this glucose for energy to grow, repair itself, and carry out all its life functions. Any extra glucose can be stored as starch for later use.\n",
            "    *   As a wonderful byproduct of this process, plants also release **oxygen** back into the air – which is what we (and most other animals) breathe to survive!\n",
            "\n",
            "So, in simple terms: **Plants use sunlight, water, and carbon dioxide to create sugar (their food) and oxygen.** It's a fundamental process that sustains almost all life on Earth!\n",
            "\n",
            "Topic 3:\n",
            " Hello John!\n",
            "\n",
            "Calculus is absolutely fundamental to many areas of data science, even if you don't always explicitly write out integrals or derivatives in your day-to-day coding. It provides the mathematical backbone for understanding how many algorithms work, especially when it comes to **optimization** and **probability**.\n",
            "\n",
            "Here are the key areas where calculus is applied in data Science:\n",
            "\n",
            "1.  **Optimization (The Big One: Finding the Best Fit)**\n",
            "    *   **Concept:** This is where **derivatives** (and partial derivatives for multiple variables) shine. The derivative tells us the rate of change of a function and, crucially, the direction of its steepest ascent or descent.\n",
            "    *   **Application:** Almost every machine learning model involves an optimization problem. Models \"learn\" by trying to find the best set of parameters (like the weights in a neural network or the coefficients in a regression model) that minimize a \"loss function\" (or cost function). The loss function measures how well the model is performing – a lower loss means better performance.\n",
            "    *   **How it works (Gradient Descent):**\n",
            "        *   To minimize the loss function, we need to find the \"bottom of the valley\" in its landscape.\n",
            "        *   **Gradient Descent** is the most common optimization algorithm. It uses the **gradient** (a vector of partial derivatives) of the loss function with respect to each parameter.\n",
            "        *   The gradient points in the direction of the steepest *increase* in the loss. To minimize the loss, we take small steps in the *opposite* direction of the gradient.\n",
            "        *   This iterative process, guided by calculus, helps the model converge to the optimal parameters.\n",
            "    *   **Examples:**\n",
            "        *   **Linear Regression:** Minimizing the Mean Squared Error (MSE) loss function.\n",
            "        *   **Logistic Regression:** Minimizing the cross-entropy loss function.\n",
            "        *   **Support Vector Machines (SVMs):** Optimizing the margin between classes.\n",
            "        *   **Neural Networks:** This is where it's most prominent (see point #4).\n",
            "\n",
            "2.  **Probability and Statistics (Understanding Distributions)**\n",
            "    *   **Concept:** **Integrals** are essential for working with continuous probability distributions.\n",
            "    *   **Application:**\n",
            "        *   **Probability Density Functions (PDFs):** For a continuous random variable, the probability of it falling within a certain range is calculated by integrating its PDF over that range.\n",
            "        *   **Expected Values:** Calculating the expected value (mean) of a continuous random variable involves integration.\n",
            "        *   **Maximum Likelihood Estimation (MLE):** This statistical method often involves taking the derivative of a likelihood function (or its logarithm) and setting it to zero to find the parameters that maximize the likelihood of observing the given data.\n",
            "\n",
            "3.  **Understanding Model Sensitivity and Feature Importance**\n",
            "    *   **Concept:** Derivatives help us understand how sensitive a model's output is to changes in its input features or parameters.\n",
            "    *   **Application:**\n",
            "        *   **Feature Importance:** By looking at the magnitude of derivatives of the model's output with respect to different input features, we can get an idea of which features have the most influence.\n",
            "        *   **Explainable AI (XAI):** Techniques like SHAP (SHapley Additive exPlanations) values often have calculus roots, helping to attribute the contribution of each feature to a prediction.\n",
            "\n",
            "4.  **Deep Learning (Backpropagation)**\n",
            "    *   **Concept:** This is perhaps the most direct and crucial application of **multivariable calculus** and the **chain rule**.\n",
            "    *   **Application:** **Backpropagation** is the algorithm that allows neural networks to learn. It efficiently calculates the *gradient* of the loss function with respect to *every single weight and bias* in the network, regardless of how many layers or neurons there are.\n",
            "    *   **How it works:** It propagates the error backward through the network, layer by layer, using the chain rule to determine how much each weight contributed to the overall error. These gradients are then used by optimization algorithms (like gradient descent) to update the weights. Without calculus, training deep neural networks would be practically impossible.\n",
            "\n",
            "5.  **Data Transformation and Feature Engineering**\n",
            "    *   While not always explicit, understanding rates of change and function behavior (calculus concepts) can guide decisions in feature engineering, such as choosing appropriate polynomial transformations, logarithmic transformations, or other non-linear mappings to make data more suitable for modeling.\n",
            "\n",
            "In summary, while data scientists often use libraries and frameworks that abstract away the explicit calculus calculations, a strong understanding of calculus (especially derivatives for optimization and integrals for probability) is vital for:\n",
            "*   **Understanding** how algorithms work under the hood.\n",
            "*   **Debugging** models when they don't perform as expected.\n",
            "*   **Choosing** the right optimization strategies.\n",
            "*   **Interpreting** model results and sensitivities.\n",
            "*   **Developing** new machine learning techniques.\n",
            "\n",
            "It's truly a cornerstone of the field!\n",
            "\n",
            "Follow-up Response:\n",
            " Yes, I do! Your name is John.\n"
          ]
        }
      ]
    }
  ]
}