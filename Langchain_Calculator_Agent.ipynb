{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjQ1alCM3B53",
        "outputId": "2b144cc4-2ec3-4988-c6e5-0bfc7cf7209c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.1/500.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "!pip install -qU langchain langchain-google-genai google-generativeai==0.8.5\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GEMINI_API_KEY_DEFAULT\")  # paste your key\n",
        "print(\" API key set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs98SBMb3YlU",
        "outputId": "826e44d8-72e2-4315-ff08-cae08ff85889"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " API key set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-classic"
      ],
      "metadata": {
        "id": "NvforOUQ0zI7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import operator as op\n",
        "from typing import Union\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "import langchain, langchain_core\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI       # to work with Gemini models\n",
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_classic.agents import AgentExecutor, create_react_agent\n",
        "\n",
        "# Custom tool description renderer\n",
        "def custom_render_text_description(tools):\n",
        "    return \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])\n",
        "\n",
        "\n",
        " # Allowed operators\n",
        "_OPS = {\n",
        "    ast.Add: op.add, ast.Sub: op.sub, ast.Mult: op.mul,\n",
        "    ast.Div: op.truediv, ast.FloorDiv: op.floordiv, ast.Mod: op.mod,\n",
        "    ast.Pow: op.pow, ast.UAdd: op.pos, ast.USub: op.neg,\n",
        "}\n",
        "\n",
        "def _eval_node(node) -> Union[int, float]:\n",
        "    # Python 3.8+ uses Constant for numbers\n",
        "    if isinstance(node, ast.Constant) and isinstance(node.value, (int, float)):\n",
        "        return node.value\n",
        "    if isinstance(node, ast.BinOp) and type(node.op) in _OPS:\n",
        "        return _OPS[type(node.op)](_eval_node(node.left), _eval_node(node.right))\n",
        "    if isinstance(node, ast.UnaryOp) and type(node.op) in _OPS:\n",
        "        return _OPS[type(node.op)](_eval_node(node.operand))\n",
        "    if isinstance(node, ast.Expr):\n",
        "        return _eval_node(node.value)\n",
        "    raise ValueError(\"Unsupported expression. Use numbers, + - * / // % ** and parentheses only.\")\n",
        "\n",
        "def safe_calc(expr: str) -> float:\n",
        "    expr = expr.strip()\n",
        "    if len(expr) > 200:\n",
        "        raise ValueError(\"Expression too long.\")\n",
        "    tree = ast.parse(expr, mode=\"eval\")\n",
        "    return float(_eval_node(tree.body))\n",
        "\n",
        "@tool\n",
        "def calculate(expression: str) -> str:\n",
        "    \"\"\"Safely evaluate arithmetic like '(12345*6789)+98765'. Returns only the number.\"\"\"\n",
        "    try:\n",
        "        val = safe_calc(expression)\n",
        "        if abs(val) > 1e18:\n",
        "            return \"Error: result too large.\"\n",
        "        # Pretty output: drop trailing .0 if it's an integer\n",
        "        return str(int(val)) if val.is_integer() else str(val)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "print(\" Calculator agent ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95SqBMFR5bMp",
        "outputId": "c82ee873-1ef0-41b9-e89e-876ac9314715"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Calculator agent ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_classic.agents import AgentExecutor, create_tool_calling_agent\n",
        "\n",
        "def build_calc_agent():\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0) # Note: Use 1.5-flash or pro\n",
        "    tools = [calculate]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a precise math assistant. Use the calculate tool for all math.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ])\n",
        "\n",
        "    # create_tool_calling_agent is compatible with ChatPromptTemplate and MessagesPlaceholder\n",
        "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "    return AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
        "\n",
        "calc_agent1 = build_calc_agent()"
      ],
      "metadata": {
        "id": "jP8jPD5wgWcR"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(calc_agent1.invoke({\"input\": \"Compute (12345*6789)+98765. Give only the number.\"})[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WrOqx6R-b_u",
        "outputId": "7a768f81-355c-484c-e690-847cff37814f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83908970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plain LLM (no tool) for comparison\n",
        "llm_plain = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "\n",
        "q1 = \"What is 234 * 19? Give only the number.\"\n",
        "q2 = \"Compute (12345*6789)+98765. Give only the number.\"\n",
        "q3 = \"What is 13.7% of 12345 plus 98.76^2? Round to 2 decimals.\"\n",
        "\n",
        "print(\"— LLM only —\")\n",
        "print(\"Q1:\", llm_plain.invoke(q1).content)\n",
        "print(\"Q2:\", llm_plain.invoke(q2).content)\n",
        "print(\"Q3:\", llm_plain.invoke(q3).content)\n",
        "\n",
        "print(\"\\n— Agent with calculator —\")\n",
        "print(\"Q1:\", calc_agent1.invoke({\"input\": q1})[\"output\"])\n",
        "print(\"Q2:\", calc_agent1.invoke({\"input\": q2})[\"output\"])\n",
        "print(\"Q3:\", calc_agent1.invoke({\"input\": q3})[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SxpbACr5uBi",
        "outputId": "ad23af98-0360-420f-b71c-7ada5ec5c84f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "— LLM only —\n",
            "Q1: 4446\n",
            "Q2: 83908970\n",
            "Q3: Let's break this down into two parts and then add them.\n",
            "\n",
            "**Part 1: 13.7% of 12345**\n",
            "To calculate a percentage of a number, convert the percentage to a decimal (divide by 100) and then multiply.\n",
            "0.137 * 12345 = 1691.265\n",
            "\n",
            "**Part 2: 98.76^2**\n",
            "This means 98.76 multiplied by itself.\n",
            "98.76 * 98.76 = 9753.5376\n",
            "\n",
            "**Add the two parts together:**\n",
            "1691.265 + 9753.5376 = 11444.8026\n",
            "\n",
            "**Round to 2 decimals:**\n",
            "The third decimal place is 2, which is less than 5, so we round down (keep the second decimal place as it is).\n",
            "11444.80\n",
            "\n",
            "So, 13.7% of 12345 plus 98.76^2 is **11444.80**.\n",
            "\n",
            "— Agent with calculator —\n",
            "Q1: 4446\n",
            "Q2: 83908970\n",
            "Q3: [{'type': 'text', 'text': '11444.80', 'extras': {'signature': 'CiQBvj72+9dTBHGuosMuQg2GbUBmlJjBHO5+oOuZne/2eQl0SHQKSQG+Pvb7moybU8SzvYhoBSbW9ZxSdhybK2PqlLzPK8dkn+DmRlb3pJ0nKt+n3ZJJ1PBwPcRJcDVEjjfXY1un02LkThfJtIuyi3QKswEBvj72+0Gam1ffQeRkPfjPhJajWqpNt1V3Kbk4DP8fEOSn76tzxKWwH3chWx7XLL2d+I+mVEDvC6YXeRMA6x9a2DpAZUenowesZCaSISWW9+4yE74qN8T0OLXoQIB/FHJ2TWA1c71WqaqSrUOOdLi/wr1xkgtJDl0OktpWJwfRtECf1IQ7DYv40LpOxNGNi7FLPcDwFKpfjP7DLMfD5uE8jRmzx3SP6rKhMdnR6hq4oUyvJQqEAQG+Pvb7UnzbL6p7bDDoUieV+VWXiyO3R3vGTzvUOMOzS00mKHbO495ZCLtjcgGmuocCSlhVukIhgSdxC2KlwDkNnRLGg0oKS0Qwjz5DJjFY2h8pyc7AHwAx1jKIJXOpyQrJJCk5MBoe0TibotYVWkndQ8TEM7flKGxGJJMm8IxlhRUymQ=='}, 'index': 0}]\n"
          ]
        }
      ]
    }
  ]
}