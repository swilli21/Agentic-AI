{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOu4LOeea-Gq",
        "outputId": "81620f73-db1c-4a12-f423-f646abf07142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/500.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m491.5/500.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "!pip install -qU langchain langchain-google-genai google-generativeai==0.8.5\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-classic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul9xrRLKNP5d",
        "outputId": "cf0b541e-a487-44a9-9321-250281fae4bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GEMINI_API_KEY_DEFAULT\")\n",
        "print(\" API key set.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHv6z0A-bDIK",
        "outputId": "53879aad-88b2-4630-879a-3742b6877dcb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " API key set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI       # to work with Gemini models\n",
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_classic.agents import AgentExecutor, create_react_agent\n"
      ],
      "metadata": {
        "id": "OUJMjl-RbPyh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Small in-memory dictionary (data source) can be replaced with a real API\n",
        "MOCK_WEATHER: Dict[str, Dict[str, str]] = {\n",
        "    \"mumbai\":  {\"condition\": \"Humid, partly cloudy\", \"temp_c\": \"31\", \"humidity\": \"75%\", \"rain_chance\": \"40%\"},\n",
        "    \"delhi\":   {\"condition\": \"Hot, dry\",             \"temp_c\": \"34\", \"humidity\": \"35%\", \"rain_chance\": \"10%\"},\n",
        "    \"hyderabad\":{\"condition\": \"Warm, breezy\",        \"temp_c\": \"30\", \"humidity\": \"55%\", \"rain_chance\": \"20%\"},\n",
        "    \"bengaluru\":{\"condition\": \"Mild, cloudy\",        \"temp_c\": \"26\", \"humidity\": \"65%\", \"rain_chance\": \"30%\"},\n",
        "}\n"
      ],
      "metadata": {
        "id": "WGz8ekjIbS9r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return the current time stamp in ist, responses look local\n",
        "def _now_ist_str() -> str:\n",
        "    ist = ZoneInfo(\"Asia/Kolkata\")\n",
        "    return datetime.now(ist).strftime(\"%Y-%m-%d %H:%M IST\")\n"
      ],
      "metadata": {
        "id": "Wx0JZIXgbZxO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accept city name as input, return a short weather report, if no cit is provided, ask the user to provide one\n",
        "Check the city name against the small dataset (dict)"
      ],
      "metadata": {
        "id": "oocGGZSOP2nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Return a short, human-friendly weather report for the given city (mock data).\"\"\"\n",
        "    if not city or not city.strip():\n",
        "        return \"Please provide a city name.\"\n",
        "    key = city.strip().lower()\n",
        "    data = MOCK_WEATHER.get(key)\n",
        "    if not data:\n",
        "        # Sensible default when city isn't in our mock set\n",
        "        data = {\"condition\": \"Partly cloudy\", \"temp_c\": \"30\", \"humidity\": \"60%\", \"rain_chance\": \"20%\"}\n",
        "    return (\n",
        "        f\"City: {city.strip().title()}\\n\"\n",
        "        f\"Time: {_now_ist_str()}\\n\"\n",
        "        f\"Condition: {data['condition']}\\n\"\n",
        "        f\"Temperature: {data['temp_c']} °C\\n\"\n",
        "        f\"Humidity: {data['humidity']}\\n\"\n",
        "        f\"Chance of rain: {data['rain_chance']}\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "Tq0awrtGbcSV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_weather_agent():\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "    tools = [get_weather]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\",\n",
        "         \"You are a helpful weather assistant.\\n\"\n",
        "         \"You have access to the following tools:\\n\"\n",
        "         \"{tools}\\n\\n\"  # Placeholder for tool descriptions\n",
        "         \"Use the following format:\\n\\n\"\n",
        "         \"Question: the input question you must answer\\n\"\n",
        "         \"Thought: you should always think about what to do\\n\"\n",
        "         \"Action: the action to take, should be one of [{tool_names}]\\n\" # Placeholder for tool names\n",
        "         \"Action Input: the input to the action\\n\"\n",
        "         \"Observation: the result of the action\\n\"\n",
        "         \"... (this Thought/Action/Action Input/Observation can repeat N times)\\n\"\n",
        "         \"Thought: I now know the final answer\\n\"\n",
        "         \"Final Answer: the final answer to the original input question\\n\\n\"\n",
        "         \"Begin!\\n\\n\"\n",
        "         \"RULES:\\n\"\n",
        "         \"1) Always call the get_weather tool to answer weather questions.\\n\"\n",
        "         \"2) If the city is missing or unclear, ask the user to specify a city.\\n\"\n",
        "         \"3) Return concise, friendly answers.\\n\"),\n",
        "        (\"human\", \"{input}\\n{agent_scratchpad}\"), # agent_scratchpad as a string here\n",
        "    ])\n",
        "\n",
        "    agent = create_react_agent(llm, tools, prompt)\n",
        "    return AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
        "\n",
        "weather_agent = build_weather_agent()\n",
        "print(\" Weather agent ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU4Hkkz-bfn6",
        "outputId": "26f7c55d-d365-4bc3-8e78-6eb8158e244b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Weather agent ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(q: str):\n",
        "    res = weather_agent.invoke({\"input\": q})\n",
        "    print(res[\"output\"], \"\\n\")\n"
      ],
      "metadata": {
        "id": "0Fi5GTukbjx2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Known city\n",
        "ask(\"What’s the weather in Mumbai?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEb91YA5OIkB",
        "outputId": "4fed5ef5-53af-4048-fab1-6789c5503389"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Mumbai is humid and partly cloudy with a temperature of 31°C. There's a 40% chance of rain and humidity is at 75%. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another known city\n",
        "ask(\"Weather update for Bengaluru, please.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MzArF4LOKHO",
        "outputId": "1070f585-af74-43a8-b43c-d5e33743e820"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Bengaluru is currently mild and cloudy with a temperature of 26°C. There's a 30% chance of rain, and humidity is at 65%. \n",
            "\n"
          ]
        }
      ]
    }
  ]
}