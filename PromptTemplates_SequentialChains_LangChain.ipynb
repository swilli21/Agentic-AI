{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swilli21/Agentic-AI/blob/master/PromptTemplates_SequentialChains_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KZdg2a5zBqMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a497409d-65da-4c43-d10e-56b05278333a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/155.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/500.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m491.5/500.1 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.1/500.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#  Install required packages\n",
        "!pip install -qU langchain langchain-google-genai google-generativeai==0.8.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, platform\n",
        "from google.colab import userdata\n",
        "from datetime import datetime\n",
        "\n",
        "# LangChain + Gemini\n",
        "import langchain, langchain_core\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI       # to work with Gemini models\n",
        "from langchain_core.prompts import PromptTemplate               # to format prompts\n",
        "from langchain_core.output_parsers import StrOutputParser       # to extract plain text from responses\n",
        "from langchain_core.runnables import RunnablePassthrough        # to chain steps"
      ],
      "metadata": {
        "id": "M8yv_6ILBytu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Set your Gemini API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GEMINI_API_KEY_DEFAULT\")"
      ],
      "metadata": {
        "id": "zO5mtoihBzNU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature-  (typically 0 to 2+) that controls the randomness and creativity of generated text by scaling the probability distribution of the next token"
      ],
      "metadata": {
        "id": "ITTtxMdHswN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommended for demos: fast & economical\n",
        "model_name = \"gemini-2.5-flash\"\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model_name,\n",
        "    convert_system_message_to_human=True,  # smoother behavior with system prompts\n",
        "    temperature=0.7, # higher the temperature (0 to 1) allows the LLM to be creative with its reponse\n",
        ")\n",
        "print(f\" Ready with model: {model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiINCe26CVp8",
        "outputId": "7aa8d88b-53bd-4dfc-843b-d0c3280c9e19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ready with model: gemini-2.5-flash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple sequential chain (Ideas → Summary)"
      ],
      "metadata": {
        "id": "zI9cA6hIC6zF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: generate ideas\n",
        "idea_prompt = PromptTemplate.from_template(\n",
        "    \"Generate 3 creative ideas about: {topic}. Return them as a numbered list.\"\n",
        ")\n",
        "\n",
        "# Step 2: summarize the ideas\n",
        "summary_prompt = PromptTemplate.from_template(\n",
        "    \"Summarize the ideas below in 2 friendly sentences for a beginner:\\n\\n{ideas}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "7ciGGsY4Ct1i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain\n",
        "\n",
        "idea_chain = idea_prompt | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "Y1DuBEyTDE7p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequential Chain without memory\n",
        "\n",
        "- Generate the key ideas\n",
        "- The key topic is passed directly to the summary prompt\n",
        "- Then to the LLM\n",
        "- Finally to the output"
      ],
      "metadata": {
        "id": "3Tw9xSMktUsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compose a chain where the output of idea_chain is fed into the summary prompt\n",
        "sequential_chain = {\n",
        "    \"ideas\": idea_chain,\n",
        "    \"topic\": RunnablePassthrough()\n",
        "} | summary_prompt | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "e8quJB7MDIxP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"using AI to improve school homework feedback\"\n",
        "Creative_ideas = idea_chain.invoke({\"topic\": topic}) # first chain generate the topics\n",
        "summary = sequential_chain.invoke({\"topic\": topic}) # second chain passes the topics to be summarized"
      ],
      "metadata": {
        "id": "KUlWN9BjDU-v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Topic:\", topic)\n",
        "print(\" Creative Ideas : \", Creative_ideas)\n",
        "print(\" Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnSZoIT7Df-4",
        "outputId": "10e83b03-8836-4392-ad12-291796562107"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Topic: using AI to improve school homework feedback\n",
            " Creative Ideas :  Here are 3 creative ideas about using AI to improve school homework feedback:\n",
            "\n",
            "1.  **The AI \"Conceptual Coach\" with Interactive Remediation:**\n",
            "    Instead of just marking an answer wrong, an AI would act as a personalized conceptual coach. When a student submits an incorrect or incomplete answer, the AI wouldn't just give the right answer. Instead, it would engage in a **guided dialogue**, asking probing questions to help the student identify their own misunderstanding, provide scaffolded hints (e.g., \"Think about the main principle of X,\" or \"What was the first step we learned for solving Y?\"), and then offer alternative examples or analogies to clarify the concept. If the student is still struggling, the AI could generate a few **micro-practice problems** specifically tailored to the identified gap in their understanding, ensuring they master the prerequisite concept before moving on. This transforms static feedback into an active, personalized learning session.\n",
            "\n",
            "2.  **The AI \"Feedback Orchestrator\" for Teacher Insights & Curriculum Alignment:**\n",
            "    Beyond individual student feedback, an AI system could analyze homework submissions across an entire class. It would identify **common misconceptions or recurring error patterns** among students, not just for individual assignments but across units. For example, it could flag that 60% of students are struggling with the application of a specific math formula, or consistently misinterpreting a particular historical event. The AI would then generate a **\"Teacher Insights Dashboard,\"** highlighting these trends, suggesting areas for re-teaching or differentiated instruction in class, and even drafting personalized feedback *templates* for the teacher to review and approve, saving significant time while ensuring targeted, data-driven interventions. It could also cross-reference student performance with curriculum standards, showing where the class is excelling or falling behind.\n",
            "\n",
            "3.  **The AI \"Iterative Draft Buddy\" with Multi-Perspective Feedback:**\n",
            "    For assignments involving writing, problem-solving steps, or creative projects, students could submit **multiple drafts** of their homework to an AI \"Draft Buddy\" *before* the final submission. The AI would provide different \"layers\" of feedback:\n",
            "    *   **\"Clarity Coach\":** Suggesting ways to improve sentence structure, conciseness, or logical flow.\n",
            "    *   **\"Content Challenger\":** Asking critical questions to prompt deeper thinking or identify unsupported claims (\"Can you provide more evidence for this point?\", \"What are the counter-arguments to your conclusion?\").\n",
            "    *   **\"Rubric Rater\":** Providing a preliminary assessment against the teacher's rubric, highlighting areas where the student is meeting, exceeding, or falling short of expectations, and explaining *why*.\n",
            "    *   **\"Creativity Catalyst\":** Offering prompts or ideas for expanding on unique insights or exploring alternative approaches.\n",
            "    This allows students to iteratively refine their work and receive diverse feedback perspectives, fostering self-correction and higher-quality final submissions without adding extra workload for the teacher.\n",
            " Summary:\n",
            " Imagine AI helping with your homework in super smart ways! It could not only explain why an answer is wrong and guide you to the right one, but also show you *how* to think through problems more effectively. Plus, it could create a personalized learning plan with resources just for you, helping you master skills over time.\n"
          ]
        }
      ]
    }
  ]
}